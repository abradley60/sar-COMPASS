# list of scenes to download and process
scenes: [
        # ridgrecrest 
         'S1A_IW_SLC__1SDV_20190716T135159_20190716T135226_028143_032DC3_512B'
        ]

# list of corresponding bursts
# leave empty to process full scene
burst_ids : [t071_151218_iw2]

# the name of the software. This will form part of the path
# where the products are written
software : COMPASS-ISCE3

# the template for the COMPASS-RTC backscatter products
# variables are set in this file for each scene
COMPASS_template: configs/s1_cslc_geo.yaml

# folder to save all the configs we generate for each run
COMPASS_config_folder: /data/COMPASS/config

# scratch path for intermediate products
COMPASS_scratch_folder: /data/COMPASS/scratch

# save directory for final COMPASS products
# a new folder is made for each scene
COMPASS_output_folder: /data/COMPASS/outdir

# location of the unziped burstdb folder for compass
# contains sqlite files for IW and EW bursts
# https://sar-mpc.eu/files/S1_burstid_20220530.zip
COMPASS_burst_database_file: /data/COMPASS/burstdb/opera-burst-bbox-only.sqlite3

# location of earthdata credentials to download data.
earthdata_credentials: credentials/credentials_earthdata.yaml

# location of aws credentials 
aws_credentials: credentials/credentials_aws.yaml

# location of copernicus data space ecosystem credentials
copernicus_credentials: credentials/credentials_copernicus.yaml

# directory to save scenes
scene_folder: /data/scenes

# whether to unzip the safe file
unzip_scene: True

# directory where precise orbits are saved
precise_orbit_folder: /data/osv/POEORB

# directory restituted orbits are saved
restituted_orbit_folder: /data/osv/RESORB

# Absolute file path to a DEM to use (skip download process and use DEM specified)
# leave empty to ignore
# /data/dem/glo_30/S1A_IW_SLC__1SDV_20191028T131928_20191028T131947_029659_0360CA_A1A0_dem_3031.tif
dem_path: 

# directory downloaded DEM will be saved - a sub folder is made for each DEM type
dem_folder: /data/dem

# Apply ETAD corrections to the slc
# Note - These must be available locally
# A new folder {scene_folder}_ETAD will be created
apply_ETAD : False

# number of gdal threads to process the ETAD file with
gdal_threads : 4

# Folder to download and store the ETAD files
ETAD_folder : /data/ETAD

# overwrite the dem if it already exists
overwrite_dem : False

# type of dem to download for each scene
# list of valid dems in https://pypi.org/project/dem-stitcher/
# REMA must be specified with resolution - e.g. REMA_32
# valid resolutions are [2, 10, 32, 100, 500, 1000]
dem_type: glo_30
#dem_type: REMA_32

# add a prefix to the scene in the s3 bucket
# mostly for testing, leave blank to exclude
scene_prefix:

# specify the folder in the s3 bucket
s3_bucket_folder: experimental

# s3 bucket to push the results
# note, output crs (trg_crs) is set in COMPASS config
# formatting will be {s3_bucket}/{s3_bucket_folder}/{software}/{dem_type}/{trg_crs}/{prefix}{scene}/file
s3_bucket: deant-data-public-dev

# whether to push to s3
push_to_s3: True

# whether to push the DEM to the S3 bucket
upload_dem: True

# delete files after run
delete_local_files: False

# Skip the rtc process
# True will skip the COMPASS run and
# try and upload existing results for the given scenes
skip_COMPASS : False